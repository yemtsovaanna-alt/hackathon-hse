{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Хакатон \"Ритмы продаж\"",
   "id": "96d3210ed302f2a5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Вы когда-нибудь задумывались, почему цена на один и тот же товар может меняться? Или как огромный маркетплейс вроде Wildberries понимает, сколько товаров нужно заготовить на складе? В основе лежит сложный баланс между ценой и спросом: чем ниже цена, тем больше покупают. Но... насколько больше?\n",
    "В этой задаче вам предстоит заглянуть в \"машинное отделение\" одного из крупнейших маркетплейсов и поработать с данными о продажах кроссовок. У вас будут реальные обезличенные данные о продажах, ценах и остатках тысяч моделей. Сможете ли вы разгадать их взаимосвязь и научиться предсказывать будущее?\n",
    "Вам предстоит построить модель, которая сможет точно спрогнозировать, сколько единиц конкретного товара купят за один день при определённой цене.\n",
    "\n"
   ],
   "id": "c743607d50499498"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Задание:\n",
    "\n",
    "Постройте модель, которая для каждой пары товар-день в тестовом периоде предскажет точное количество проданных единиц товара."
   ],
   "id": "e2e7f0bb463521ba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Данные:<br>\n",
    "train.parquet - история продаж за определенный период.<br>\n",
    "test.parquet - данные за 14 дней, следующих сразу за обучающим набором.<br>\n",
    "sample_submission.csv - файл-шаблон для отправки вашего решения.<br>\n",
    "Файлы train.parquet и test.parquet содержат:<br>\n",
    "nm_id - анонимный идентификатор товара.<br>\n",
    "dt - дата.<br>\n",
    "price - цена товара в этот день.<br>\n",
    "is_promo - флаг участия товара в промо-акции.<br>\n",
    "prev_leftovers - остаток товара на складе на начало дня.<br>\n",
    "qty - количество проданных единиц, присутствует только в train. Это ваш таргет<br>\n"
   ],
   "id": "a10a3180daf24cda"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Метрика:\n",
    "Качество вашего решения будет оцениваться с помощью метрики взвешенной MAE (wMAE). Так как в данных много дней с нулевыми продажами, мы усиливаем вклад дней, когда продажи были, ведь ошибка в них критичнее.\n",
    "Веса определяются следующим образом:\n",
    "\n",
    "$$\n",
    "w_i =\n",
    "\\begin{cases}\n",
    "1, & \\text{если } y_i = 0 \\\\\n",
    "7, & \\text{если } y_i > 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "Итоговая формула метрики:\n",
    "$$\n",
    "\\mathrm{MAE}=\\frac{1}{n}\\sum_{i=1}^{n}\\lvert y_i-\\hat{y}_i\\rvert\n",
    "$$\n",
    "\n",
    "\n",
    "где $y_i$ — истинное значение продаж, а $\\hat{y}_i$ — ваш прогноз.\n",
    "\n",
    "**Примечание.** Вес для дней с продажами $w_{\\text{pos}} = 7$ был выбран не случайно. Он рассчитан по обучающей выборке так, чтобы сбалансировать общую сумму весов для обоих классов, исходя из доли дней с продажами $p \\approx 0.13$.\n",
    "\n",
    "\n"
   ],
   "id": "8ec2f3a9ff633676"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "id": "60b1aa63959a605b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "TRAIN_PATH = \"/Users/slvic/Downloads/train.parquet\"\n",
    "TEST_PATH = \"/Users/slvic/Downloads/test.parquet\"\n",
    "SUB_PATH = \"/Users/slvic/Downloads/sample_submission.csv\"\n",
    "\n",
    "train = pd.read_parquet(TRAIN_PATH)\n",
    "test = pd.read_parquet(TEST_PATH)\n",
    "sub = pd.read_csv(SUB_PATH)\n",
    "\n",
    "print(\"train:\", train.shape)\n",
    "print(\"test :\", test.shape)\n",
    "print(\"sub  :\", sub.shape)\n",
    "\n",
    "display(train.head(3))\n",
    "display(test.head(3))\n",
    "display(sub.head(3))\n"
   ],
   "id": "7693993ba8179721"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train[\"dt\"] = pd.to_datetime(train[\"dt\"], errors=\"coerce\")\n",
    "test[\"dt\"]  = pd.to_datetime(test[\"dt\"], errors=\"coerce\")\n",
    "\n",
    "def date_range_info(df, name):\n",
    "    dmin = df[\"dt\"].min()\n",
    "    dmax = df[\"dt\"].max()\n",
    "    ndays = df[\"dt\"].nunique()\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  min dt: {dmin}\")\n",
    "    print(f\"  max dt: {dmax}\")\n",
    "    print(f\"  unique days: {ndays}\")\n",
    "    print(f\"  rows: {len(df):,}\")\n",
    "    print()\n",
    "\n",
    "date_range_info(train, \"TRAIN\")\n",
    "date_range_info(test, \"TEST\")\n",
    "\n",
    "\n",
    "train_max = train[\"dt\"].max()\n",
    "test_min  = test[\"dt\"].min()\n",
    "\n",
    "print(\"Continuity check:\")\n",
    "print(\"  train_max:\", train_max)\n",
    "print(\"  test_min :\", test_min)\n",
    "print(\"  gap (days):\", (test_min - train_max).days)\n",
    "\n",
    "\n",
    "test_days = sorted(test[\"dt\"].dropna().unique())\n",
    "print(\"\\nTEST days count:\", len(test_days))\n",
    "print(\"First 5 test days:\", test_days[:5])\n",
    "print(\"Last  5 test days:\", test_days[-5:])\n"
   ],
   "id": "a2b6c8ac11a3a8c5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Промежуточные выводы по данным** <br>\n",
    "В трейне дана история продаж с 04.07.2024 по 07.07.2025 (369 дней).<br>\n",
    "В тесте дана история продаж с 08.07.2025 по 21.07.2025 (14 дней).<br>\n"
   ],
   "id": "4707a9d4f840a393"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "plt.rcParams[\"font.size\"] = 11"
   ],
   "id": "769febd419334e32"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Разведочный анализ (Exploratory Deep Dive)",
   "id": "12126bec16c6b455"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1.1 Профилирование таргета\n",
    "Распределение qty, доля нулей, выбросы"
   ],
   "id": "43976b5b53ff4971"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "axes[0].hist(train[\"qty\"], bins=50, edgecolor=\"black\")\n",
    "axes[0].set_title(\"Распределение qty (все)\")\n",
    "axes[0].set_xlabel(\"qty\")\n",
    "axes[0].set_ylabel(\"Частота\")\n",
    "\n",
    "qty_pos = train.loc[train[\"qty\"] > 0, \"qty\"]\n",
    "axes[1].hist(qty_pos, bins=50, edgecolor=\"black\", color=\"orange\")\n",
    "axes[1].set_title(f\"Распределение qty > 0 (n={len(qty_pos):,})\")\n",
    "axes[1].set_xlabel(\"qty\")\n",
    "\n",
    "zero_rate = (train[\"qty\"] == 0).mean()\n",
    "axes[2].bar([\"qty = 0\", \"qty > 0\"], [zero_rate, 1 - zero_rate],\n",
    "            color=[\"steelblue\", \"orange\"])\n",
    "axes[2].set_title(f\"Доля нулей: {zero_rate:.1%}\")\n",
    "axes[2].set_ylabel(\"Доля\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Статистики qty:\")\n",
    "print(train[\"qty\"].describe())\n",
    "print(f\"\\nПерцентили qty > 0:\")\n",
    "print(qty_pos.describe(percentiles=[0.5, 0.75, 0.9, 0.95, 0.99]))"
   ],
   "id": "c862abac03356644"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1.2 Временные паттерны\n",
    "Средние продажи по дням недели, месяцам; тренд"
   ],
   "id": "d55ebcb65f1ba651"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train[\"dow\"] = train[\"dt\"].dt.dayofweek\n",
    "train[\"month\"] = train[\"dt\"].dt.month\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# По дням недели\n",
    "dow_names = [\"Пн\", \"Вт\", \"Ср\", \"Чт\", \"Пт\", \"Сб\", \"Вс\"]\n",
    "dow_stats = train.groupby(\"dow\")[\"qty\"].mean()\n",
    "axes[0].bar(dow_names, dow_stats.values, color=\"steelblue\")\n",
    "axes[0].set_title(\"Средние продажи по дням недели\")\n",
    "axes[0].set_ylabel(\"mean qty\")\n",
    "\n",
    "# По месяцам\n",
    "month_stats = train.groupby(\"month\")[\"qty\"].mean()\n",
    "axes[1].bar(month_stats.index, month_stats.values, color=\"coral\")\n",
    "axes[1].set_title(\"Средние продажи по месяцам\")\n",
    "axes[1].set_xlabel(\"Месяц\")\n",
    "axes[1].set_ylabel(\"mean qty\")\n",
    "\n",
    "# Тренд: средние продажи по дням\n",
    "daily = train.groupby(\"dt\")[\"qty\"].mean().reset_index()\n",
    "axes[2].plot(daily[\"dt\"], daily[\"qty\"], alpha=0.5, linewidth=0.8)\n",
    "axes[2].set_title(\"Средние дневные продажи (тренд)\")\n",
    "axes[2].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Доля ненулевых продаж по дням недели\n",
    "sell_rate_dow = train.groupby(\"dow\")[\"qty\"].apply(lambda x: (x > 0).mean())\n",
    "print(\"Доля дней с продажами по дням недели:\")\n",
    "for i, d in enumerate(dow_names):\n",
    "    print(f\"  {d}: {sell_rate_dow.iloc[i]:.2%}\")"
   ],
   "id": "1bbb616b9232e65e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1.3 Ценовая эластичность и промо-эффект\n",
    "Связь цены со спросом; влияние промо на продажи"
   ],
   "id": "374e3bd8861cc606"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Цена vs qty (scatter на сэмпле)\n",
    "sample = train.sample(min(10_000, len(train)), random_state=42)\n",
    "axes[0].scatter(sample[\"price\"], sample[\"qty\"], alpha=0.15, s=5)\n",
    "axes[0].set_title(\"Цена vs Продажи\")\n",
    "axes[0].set_xlabel(\"price\")\n",
    "axes[0].set_ylabel(\"qty\")\n",
    "\n",
    "# Промо vs не-промо\n",
    "promo_stats = train.groupby(\"is_promo\")[\"qty\"].agg([\"mean\", \"sum\", \"count\"])\n",
    "promo_stats[\"sell_rate\"] = train.groupby(\"is_promo\")[\"qty\"].apply(lambda x: (x > 0).mean()).values\n",
    "print(\"Статистики по промо:\")\n",
    "display(promo_stats)\n",
    "\n",
    "labels = [\"Без промо\", \"С промо\"]\n",
    "axes[1].bar(labels, promo_stats[\"mean\"].values, color=[\"steelblue\", \"orange\"])\n",
    "axes[1].set_title(\"Средние продажи: промо vs обычные\")\n",
    "axes[1].set_ylabel(\"mean qty\")\n",
    "\n",
    "axes[2].bar(labels, promo_stats[\"sell_rate\"].values, color=[\"steelblue\", \"orange\"])\n",
    "axes[2].set_title(\"Доля дней с продажами: промо vs обычные\")\n",
    "axes[2].set_ylabel(\"sell rate\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "37749b3a0ace5be6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1.4 Анализ остатков на складе\n",
    "Связь prev_leftovers → qty; порог дефицита"
   ],
   "id": "7b099fcf9eeef041"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Остатки vs qty\n",
    "axes[0].scatter(sample[\"prev_leftovers\"], sample[\"qty\"], alpha=0.15, s=5)\n",
    "axes[0].set_title(\"Остатки vs Продажи\")\n",
    "axes[0].set_xlabel(\"prev_leftovers\")\n",
    "axes[0].set_ylabel(\"qty\")\n",
    "\n",
    "# Нулевые остатки = нулевые продажи?\n",
    "zero_stock = train[train[\"prev_leftovers\"] == 0]\n",
    "print(f\"Строк с нулевыми остатками: {len(zero_stock):,} ({len(zero_stock)/len(train):.2%})\")\n",
    "print(f\"Из них с qty > 0: {(zero_stock['qty'] > 0).sum()} ({(zero_stock['qty'] > 0).mean():.2%})\")\n",
    "\n",
    "# Бины остатков\n",
    "train[\"stock_bin\"] = pd.cut(train[\"prev_leftovers\"],\n",
    "                            bins=[0, 5, 20, 50, 100, 500, float(\"inf\")],\n",
    "                            labels=[\"1-5\", \"6-20\", \"21-50\", \"51-100\", \"101-500\", \"500+\"])\n",
    "stock_agg = train[train[\"prev_leftovers\"] > 0].groupby(\"stock_bin\", observed=True)[\"qty\"].agg([\"mean\", \"count\"])\n",
    "stock_agg[\"sell_rate\"] = train[train[\"prev_leftovers\"] > 0].groupby(\"stock_bin\", observed=True)[\"qty\"].apply(lambda x: (x > 0).mean()).values\n",
    "\n",
    "axes[1].bar(stock_agg.index.astype(str), stock_agg[\"mean\"], color=\"teal\")\n",
    "axes[1].set_title(\"Средние продажи по бинам остатков\")\n",
    "axes[1].set_xlabel(\"prev_leftovers bin\")\n",
    "axes[1].set_ylabel(\"mean qty\")\n",
    "\n",
    "axes[2].bar(stock_agg.index.astype(str), stock_agg[\"sell_rate\"], color=\"teal\")\n",
    "axes[2].set_title(\"Доля дней с продажами по бинам остатков\")\n",
    "axes[2].set_ylabel(\"sell rate\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "train.drop(columns=[\"stock_bin\"], inplace=True)"
   ],
   "id": "1dcf9d46ec26c26"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1.5 Товарная сегментация\n",
    "Кластеры товаров по объёму продаж; пересечение товаров train ↔ test"
   ],
   "id": "3d81894ea9f150d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "item_stats = train.groupby(\"nm_id\").agg(\n",
    "    total_qty=(\"qty\", \"sum\"),\n",
    "    mean_qty=(\"qty\", \"mean\"),\n",
    "    sell_rate=(\"qty\", lambda x: (x > 0).mean()),\n",
    "    n_days=(\"dt\", \"nunique\"),\n",
    "    avg_price=(\"price\", \"mean\"),\n",
    ").reset_index()\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "axes[0].hist(item_stats[\"total_qty\"], bins=50, edgecolor=\"black\")\n",
    "axes[0].set_title(\"Распределение суммарных продаж по товарам\")\n",
    "axes[0].set_xlabel(\"total qty\")\n",
    "\n",
    "axes[1].hist(item_stats[\"sell_rate\"], bins=50, edgecolor=\"black\", color=\"orange\")\n",
    "axes[1].set_title(\"Распределение sell_rate по товарам\")\n",
    "axes[1].set_xlabel(\"sell rate (доля дней с продажами)\")\n",
    "\n",
    "axes[2].hist(item_stats[\"avg_price\"], bins=50, edgecolor=\"black\", color=\"teal\")\n",
    "axes[2].set_title(\"Распределение средней цены по товарам\")\n",
    "axes[2].set_xlabel(\"avg price\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Пересечение товаров\n",
    "train_items = set(train[\"nm_id\"].unique())\n",
    "test_items = set(test[\"nm_id\"].unique())\n",
    "overlap = train_items & test_items\n",
    "only_train = train_items - test_items\n",
    "only_test = test_items - train_items\n",
    "\n",
    "print(f\"Товаров в train: {len(train_items)}\")\n",
    "print(f\"Товаров в test:  {len(test_items)}\")\n",
    "print(f\"Пересечение:     {len(overlap)}\")\n",
    "print(f\"Только в train:  {len(only_train)}\")\n",
    "print(f\"Только в test:   {len(only_test)}\")\n",
    "\n",
    "# Топ-10 товаров по продажам\n",
    "top10 = item_stats.nlargest(10, \"total_qty\")[[\"nm_id\", \"total_qty\", \"mean_qty\", \"sell_rate\", \"avg_price\"]]\n",
    "print(\"\\nТоп-10 товаров по суммарным продажам:\")\n",
    "display(top10)"
   ],
   "id": "700ec6dc6e5cecc7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 2. Предобработка и очистка (Data Sanitization)\n",
    "- Обработка аномалий и выбросов\n",
    "- Фильтрация \"мёртвых\" товаров (нулевые остатки)\n",
    "- Объединение train и test для единого feature engineering"
   ],
   "id": "a12562f0ea34a5a4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Перечитаем чистые данные для пайплайна\n",
    "train = pd.read_parquet(TRAIN_PATH)\n",
    "test = pd.read_parquet(TEST_PATH)\n",
    "sub = pd.read_csv(SUB_PATH)\n",
    "\n",
    "train[\"dt\"] = pd.to_datetime(train[\"dt\"])\n",
    "test[\"dt\"] = pd.to_datetime(test[\"dt\"])\n",
    "\n",
    "# Помечаем источник\n",
    "train[\"is_test\"] = 0\n",
    "test[\"is_test\"] = 1\n",
    "test[\"qty\"] = np.nan\n",
    "\n",
    "# Объединяем\n",
    "df = pd.concat([train, test], ignore_index=True)\n",
    "df = df.sort_values([\"nm_id\", \"dt\"]).reset_index(drop=True)\n",
    "\n",
    "print(f\"Объединённый датасет: {df.shape}\")\n",
    "print(f\"Train строк: {(df['is_test'] == 0).sum():,}\")\n",
    "print(f\"Test строк:  {(df['is_test'] == 1).sum():,}\")"
   ],
   "id": "3ee4b2a1ccebe8e5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================\n",
    "# 2.x Удаление выбросов в train/val и логарифмирование при необходимости\n",
    "# ============================================================\n",
    "# Логика:\n",
    "#  - Выбросы: значения числовых признаков, строго превышающие 0.996-квантиль (по train-части)\n",
    "#  - Удаляем такие строки ТОЛЬКО в train-части (включая будущую валидацию). Тест не трогаем.\n",
    "#  - Если после удаления выбросов по ящику с усами (IQR) у цены всё ещё есть выбросы, добавляем лог-признак для цены.\n",
    "\n",
    "num_cols = []\n",
    "for c in [\"qty\", \"price\", \"prev_leftovers\"]:\n",
    "    if c in df.columns:\n",
    "        num_cols.append(c)\n",
    "\n",
    "train_mask = df[\"is_test\"] == 0\n",
    "removed_info = {}\n",
    "\n",
    "# 0.996-квантили считаем по train-части\n",
    "quantiles_996 = {c: df.loc[train_mask, c].quantile(0.996) for c in num_cols}\n",
    "\n",
    "# Мастер-маска: строка помечается к удалению, если в ЛЮБОМ числе > квантиля\n",
    "remove_mask = train_mask.copy() & False\n",
    "for c in num_cols:\n",
    "    thr = quantiles_996[c]\n",
    "    over_thr = train_mask & (df[c] > thr)  # строго > квантиля\n",
    "    removed_info[c] = int(over_thr.sum())\n",
    "    remove_mask = remove_mask | over_thr\n",
    "\n",
    "removed_total = int(remove_mask.sum())\n",
    "if removed_total > 0:\n",
    "    df = df.loc[~remove_mask].reset_index(drop=True)\n",
    "\n",
    "print(\"0.996-квантили (train):\")\n",
    "for c in num_cols:\n",
    "    print(f\"  {c}: {quantiles_996[c]:.6g}\")\n",
    "print(f\"Удалено строк суммарно (train/val): {removed_total:,}\")\n",
    "print(\"Вклад по столбцам (строк, где признак > квантиля):\")\n",
    "for c in num_cols:\n",
    "    print(f\"  {c}: {removed_info[c]:,}\")\n",
    "\n",
    "# Проверка по IQR для цены: если остались выбросы — добавим лог-цену\n",
    "if \"price\" in df.columns:\n",
    "    s = df.loc[df[\"is_test\"] == 0, \"price\"].astype(float)\n",
    "    q1, q3 = s.quantile(0.25), s.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower, upper = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "    has_outliers_price = bool(((s < lower) | (s > upper)).any())\n",
    "    if has_outliers_price:\n",
    "        # Логарифмируем цену (добавляем отдельный признак, базовую цену не трогаем)\n",
    "        df[\"log_price\"] = np.log1p(df[\"price\"])\n",
    "        print(\"По IQR для 'price' остались выбросы — добавлен признак log_price.\")\n",
    "    else:\n",
    "        print(\"По IQR для 'price' выбросов не осталось.\")\n",
    "\n",
    "# Для prev_leftovers лог-признак создаётся далее (log_leftovers),\n",
    "# поэтому отдельно ничего не делаем здесь.\n"
   ],
   "id": "93fb4a820f6f4db6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 3. Конструирование признаков (Feature Engineering)\n",
    "Ключевой этап пайплайна. Создаём признаки на объединённом датасете, чтобы лаги корректно \"перетекали\" из train в test.\n",
    "\n",
    "### 3.1 Календарные признаки\n",
    "### 3.2 Лаговые и скользящие признаки (per-item)\n",
    "### 3.3 Ценовые признаки\n",
    "### 3.4 Признаки остатков\n",
    "### 3.5 Агрегатные признаки товара (item-level statics)\n",
    "### 3.6 Тренд-признаки"
   ],
   "id": "7444c9c42bf9cc9e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================\n",
    "# 3.1 Календарные признаки\n",
    "# ============================================================\n",
    "df[\"dow\"] = df[\"dt\"].dt.dayofweek          # 0=Пн, 6=Вс\n",
    "df[\"is_weekend\"] = (df[\"dow\"] >= 5).astype(int)\n",
    "df[\"day_of_month\"] = df[\"dt\"].dt.day\n",
    "df[\"week_of_year\"] = df[\"dt\"].dt.isocalendar().week.astype(int)\n",
    "df[\"month\"] = df[\"dt\"].dt.month\n",
    "df[\"day_of_year\"] = df[\"dt\"].dt.dayofyear\n",
    "\n",
    "print(\"Календарные признаки добавлены:\", [\"dow\", \"is_weekend\", \"day_of_month\", \"week_of_year\", \"month\", \"day_of_year\"])"
   ],
   "id": "1e70e748e5490b8d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================\n",
    "# 3.2 Лаговые и скользящие признаки (per-item)\n",
    "# ============================================================\n",
    "# Важно: лаги считаем ТОЛЬКО по train-части qty (NaN в test не портит)\n",
    "\n",
    "df = df.sort_values([\"nm_id\", \"dt\"]).reset_index(drop=True)\n",
    "\n",
    "lag_days = [1, 2, 3, 7, 14, 28]\n",
    "rolling_windows = [3, 7, 14, 28]\n",
    "\n",
    "for lag in lag_days:\n",
    "    df[f\"qty_lag_{lag}\"] = df.groupby(\"nm_id\")[\"qty\"].shift(lag)\n",
    "\n",
    "for w in rolling_windows:\n",
    "    rolled = df.groupby(\"nm_id\")[\"qty\"].shift(1).groupby(df[\"nm_id\"]).rolling(w, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "    df[f\"qty_rmean_{w}\"] = rolled\n",
    "\n",
    "for w in rolling_windows:\n",
    "    rolled = df.groupby(\"nm_id\")[\"qty\"].shift(1).groupby(df[\"nm_id\"]).rolling(w, min_periods=1).std().reset_index(level=0, drop=True)\n",
    "    df[f\"qty_rstd_{w}\"] = rolled\n",
    "\n",
    "# EWM\n",
    "ewm_spans = [7, 14]\n",
    "for span in ewm_spans:\n",
    "    shifted = df.groupby(\"nm_id\")[\"qty\"].shift(1)\n",
    "    ewm_val = shifted.groupby(df[\"nm_id\"]).apply(lambda x: x.ewm(span=span, min_periods=1).mean()).reset_index(level=0, drop=True)\n",
    "    df[f\"qty_ewm_{span}\"] = ewm_val\n",
    "\n",
    "# Скользящая доля ненулевых продаж\n",
    "for w in [7, 14, 28]:\n",
    "    shifted = df.groupby(\"nm_id\")[\"qty\"].shift(1)\n",
    "    sell_flag = (shifted > 0).astype(float)\n",
    "    sr = sell_flag.groupby(df[\"nm_id\"]).rolling(w, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "    df[f\"sell_rate_{w}\"] = sr\n",
    "\n",
    "lag_cols = [c for c in df.columns if \"qty_lag\" in c or \"qty_rmean\" in c or \"qty_rstd\" in c or \"qty_ewm\" in c or \"sell_rate_\" in c]\n",
    "\n",
    "# === FORWARD-FILL: заполняем NaN в лаговых фичах последним известным значением ===\n",
    "# Без этого 93% лаговых фичей в test = NaN (т.к. qty в test = NaN)\n",
    "print(\"NaN в лаговых фичах ДО forward-fill (test):\")\n",
    "test_mask = df[\"is_test\"] == 1\n",
    "print(df.loc[test_mask, lag_cols].isnull().sum().sort_values(ascending=False).head(5))\n",
    "\n",
    "for col in lag_cols:\n",
    "    df[col] = df.groupby(\"nm_id\")[col].ffill()\n",
    "\n",
    "print(f\"\\nNaN в лаговых фичах ПОСЛЕ forward-fill (test):\")\n",
    "print(df.loc[test_mask, lag_cols].isnull().sum().sort_values(ascending=False).head(5))\n",
    "\n",
    "print(f\"\\nЛаговых/скользящих признаков: {len(lag_cols)}\")\n",
    "print(lag_cols)"
   ],
   "id": "b4daf4cefeafb488"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================\n",
    "# 3.3 Ценовые признаки\n",
    "# ============================================================\n",
    "\n",
    "# Средняя цена товара (считаем только по train)\n",
    "train_mask = df[\"is_test\"] == 0\n",
    "item_avg_price = df.loc[train_mask].groupby(\"nm_id\")[\"price\"].mean().rename(\"item_avg_price\")\n",
    "df = df.merge(item_avg_price, on=\"nm_id\", how=\"left\")\n",
    "\n",
    "# Отношение текущей цены к средней (> 1 = дороже обычного)\n",
    "df[\"price_ratio\"] = df[\"price\"] / df[\"item_avg_price\"]\n",
    "df[\"price_ratio\"] = df[\"price_ratio\"].fillna(1.0)\n",
    "\n",
    "# Изменение цены за 1 день\n",
    "df[\"price_diff_1\"] = df.groupby(\"nm_id\")[\"price\"].diff(1)\n",
    "\n",
    "# Скользящее среднее цены за 7 дней\n",
    "df[\"price_rmean_7\"] = (\n",
    "    df.groupby(\"nm_id\")[\"price\"]\n",
    "    .shift(1)\n",
    "    .groupby(df[\"nm_id\"])\n",
    "    .rolling(7, min_periods=1)\n",
    "    .mean()\n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "df[\"price_vs_rmean7\"] = df[\"price\"] / df[\"price_rmean_7\"]\n",
    "df[\"price_vs_rmean7\"] = df[\"price_vs_rmean7\"].fillna(1.0)\n",
    "\n",
    "# Глубина скидки (если промо)\n",
    "df[\"discount_depth\"] = (df[\"item_avg_price\"] - df[\"price\"]) / df[\"item_avg_price\"]\n",
    "df[\"discount_depth\"] = df[\"discount_depth\"].clip(-1, 1)\n",
    "\n",
    "price_feats = [\"price_ratio\", \"price_diff_1\", \"price_rmean_7\", \"price_vs_rmean7\", \"discount_depth\", \"item_avg_price\"]\n",
    "print(f\"Ценовых признаков: {len(price_feats)}\")\n",
    "print(price_feats)"
   ],
   "id": "28d4836e4c6be098"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================\n",
    "# 3.4 Признаки остатков\n",
    "# ============================================================\n",
    "\n",
    "# Лог-остатки (для нелинейной связи)\n",
    "df[\"log_leftovers\"] = np.log1p(df[\"prev_leftovers\"])\n",
    "\n",
    "# Низкий остаток (может ограничивать продажи)\n",
    "df[\"low_stock\"] = (df[\"prev_leftovers\"] <= 5).astype(int)\n",
    "df[\"zero_stock\"] = (df[\"prev_leftovers\"] == 0).astype(int)\n",
    "\n",
    "# Дней запаса (prev_leftovers / среднее qty за 7 дней)\n",
    "df[\"days_of_stock\"] = df[\"prev_leftovers\"] / df[\"qty_rmean_7\"].replace(0, np.nan)\n",
    "df[\"days_of_stock\"] = df[\"days_of_stock\"].clip(0, 1000).fillna(1000)\n",
    "\n",
    "# Изменение остатков за 1 день\n",
    "df[\"leftovers_diff_1\"] = df.groupby(\"nm_id\")[\"prev_leftovers\"].diff(1)\n",
    "\n",
    "stock_feats = [\"log_leftovers\", \"low_stock\", \"zero_stock\", \"days_of_stock\", \"leftovers_diff_1\"]\n",
    "print(f\"Признаков остатков: {len(stock_feats)}\")\n",
    "print(stock_feats)"
   ],
   "id": "3c04ba15fb95d49b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================\n",
    "# 3.5 Агрегатные признаки товара (item-level statics)\n",
    "# ============================================================\n",
    "# Считаем ТОЛЬКО по train-части, чтобы не было утечки\n",
    "\n",
    "train_part = df[df[\"is_test\"] == 0]\n",
    "\n",
    "item_agg = train_part.groupby(\"nm_id\").agg(\n",
    "    item_total_qty=(\"qty\", \"sum\"),\n",
    "    item_mean_qty=(\"qty\", \"mean\"),\n",
    "    item_median_qty=(\"qty\", \"median\"),\n",
    "    item_max_qty=(\"qty\", \"max\"),\n",
    "    item_std_qty=(\"qty\", \"std\"),\n",
    "    item_sell_rate=(\"qty\", lambda x: (x > 0).mean()),\n",
    "    item_n_days=(\"dt\", \"nunique\"),\n",
    "    item_price_std=(\"price\", \"std\"),\n",
    "    item_mean_leftovers=(\"prev_leftovers\", \"mean\"),\n",
    "    item_promo_rate=(\"is_promo\", \"mean\"),\n",
    ").reset_index()\n",
    "\n",
    "item_agg[\"item_std_qty\"] = item_agg[\"item_std_qty\"].fillna(0)\n",
    "\n",
    "df = df.merge(item_agg, on=\"nm_id\", how=\"left\")\n",
    "\n",
    "# \"Возраст\" товара: сколько дней от первого появления\n",
    "item_first = train_part.groupby(\"nm_id\")[\"dt\"].min().rename(\"item_first_dt\")\n",
    "df = df.merge(item_first, on=\"nm_id\", how=\"left\")\n",
    "df[\"item_age\"] = (df[\"dt\"] - df[\"item_first_dt\"]).dt.days\n",
    "df.drop(columns=[\"item_first_dt\"], inplace=True)\n",
    "\n",
    "item_feats = [c for c in item_agg.columns if c != \"nm_id\"] + [\"item_age\"]\n",
    "print(f\"Агрегатных признаков товара: {len(item_feats)}\")\n",
    "print(item_feats)"
   ],
   "id": "158c8b8bb06fee50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================\n",
    "# 3.6 Тренд-признаки\n",
    "# ============================================================\n",
    "\n",
    "# Отношение средних продаж за последнюю неделю к предпоследней\n",
    "df[\"qty_ratio_w1_w2\"] = df[\"qty_rmean_7\"] / df[\"qty_rmean_14\"].replace(0, np.nan)\n",
    "df[\"qty_ratio_w1_w2\"] = df[\"qty_ratio_w1_w2\"].fillna(1.0).clip(0, 10)\n",
    "\n",
    "# Отношение средних продаж за последние 7 дней к последним 28 дням\n",
    "df[\"qty_ratio_w1_m1\"] = df[\"qty_rmean_7\"] / df[\"qty_rmean_28\"].replace(0, np.nan)\n",
    "df[\"qty_ratio_w1_m1\"] = df[\"qty_ratio_w1_m1\"].fillna(1.0).clip(0, 10)\n",
    "\n",
    "# === Индикатор устаревшости лагов ===\n",
    "# Для test-строк: сколько дней прошло с конца train → модель знает, что лаги «замороженные»\n",
    "train_max_dt = df.loc[df[\"is_test\"] == 0, \"dt\"].max()\n",
    "df[\"days_since_train\"] = (df[\"dt\"] - train_max_dt).dt.days.clip(lower=0)\n",
    "\n",
    "trend_feats = [\"qty_ratio_w1_w2\", \"qty_ratio_w1_m1\", \"days_since_train\"]\n",
    "print(f\"Тренд-признаков: {len(trend_feats)}\")\n",
    "print(trend_feats)\n",
    "\n",
    "# ============================================================\n",
    "# Финальный набор фичей\n",
    "# ============================================================\n",
    "feature_cols = (\n",
    "    [\"price\", \"is_promo\", \"prev_leftovers\"]\n",
    "    + [\"dow\", \"is_weekend\", \"day_of_month\", \"week_of_year\", \"month\", \"day_of_year\"]\n",
    "    + lag_cols\n",
    "    + price_feats\n",
    "    + stock_feats\n",
    "    + item_feats\n",
    "    + trend_feats\n",
    ")\n",
    "\n",
    "print(f\"\\nИтого признаков: {len(feature_cols)}\")\n",
    "print(f\"\\nПроверка NaN в test (топ-10):\")\n",
    "test_part = df[df[\"is_test\"] == 1]\n",
    "nan_counts = test_part[feature_cols].isnull().sum().sort_values(ascending=False)\n",
    "print(nan_counts[nan_counts > 0].head(10) if (nan_counts > 0).any() else \"NaN нет!\")"
   ],
   "id": "ff0c6f76b252db60"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Добавим log_price в список признаков при наличии\n",
    "if \"log_price\" in df.columns and \"log_price\" not in feature_cols:\n",
    "    feature_cols = [\"log_price\"] + feature_cols\n",
    "print(\"log_price in feature_cols:\", \"log_price\" in feature_cols)"
   ],
   "id": "18dfe0dd35846768"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 4. Стратегия валидации (Validation Design)\n",
    "- **Time-based holdout**: последние 14 дней train как валидация (имитация теста)\n",
    "- **Кастомная метрика wMAE**: w=7 для qty>0, w=1 для qty=0\n",
    "- Исключаем первые ~28 дней из-за NaN в лаговых признаках"
   ],
   "id": "3c1c93d0bc142f3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================\n",
    "# Кастомная метрика wMAE\n",
    "# ============================================================\n",
    "def weighted_mae(y_true, y_pred, w_pos=7, w_zero=1):\n",
    "    \"\"\"Взвешенная MAE: вес w_pos для y>0, вес w_zero для y=0.\"\"\"\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    weights = np.where(y_true > 0, w_pos, w_zero)\n",
    "    return np.average(np.abs(y_true - y_pred), weights=weights)\n",
    "\n",
    "# ============================================================\n",
    "# Train / Validation split (time-based)\n",
    "# ============================================================\n",
    "train_df = df[df[\"is_test\"] == 0].copy()\n",
    "test_df = df[df[\"is_test\"] == 1].copy()\n",
    "\n",
    "# Валидация = последние 14 дней train\n",
    "val_cutoff = train_df[\"dt\"].max() - pd.Timedelta(days=13)\n",
    "print(f\"Val cutoff: {val_cutoff.date()}  →  val period: {val_cutoff.date()} - {train_df['dt'].max().date()}\")\n",
    "\n",
    "# Исключаем первые 28 дней (NaN в лагах)\n",
    "train_start = train_df[\"dt\"].min() + pd.Timedelta(days=28)\n",
    "print(f\"Train start (после прогрева лагов): {train_start.date()}\")\n",
    "\n",
    "tr = train_df[(train_df[\"dt\"] >= train_start) & (train_df[\"dt\"] < val_cutoff)].copy()\n",
    "val = train_df[train_df[\"dt\"] >= val_cutoff].copy()\n",
    "\n",
    "print(f\"\\nTrain: {len(tr):,} строк, {tr['dt'].min().date()} — {tr['dt'].max().date()}\")\n",
    "print(f\"Val:   {len(val):,} строк, {val['dt'].min().date()} — {val['dt'].max().date()}\")\n",
    "\n",
    "X_tr = tr[feature_cols]\n",
    "y_tr = tr[\"qty\"]\n",
    "X_val = val[feature_cols]\n",
    "y_val = val[\"qty\"]\n",
    "X_test = test_df[feature_cols]\n",
    "\n",
    "# Веса для обучения\n",
    "w_tr = np.where(y_tr > 0, 7.0, 1.0)\n",
    "w_val = np.where(y_val > 0, 7.0, 1.0)\n",
    "\n",
    "print(f\"\\nX_tr: {X_tr.shape}, X_val: {X_val.shape}, X_test: {X_test.shape}\")"
   ],
   "id": "95f5ad49b1b5dfb2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 5. Моделирование (Modeling)\n",
    "\n",
    "### 5.1 Baseline — среднее за последние 7 дней\n",
    "### 5.2 LightGBM с sample_weight\n",
    "### 5.3 CatBoost с sample_weight\n",
    "### 5.4 Two-stage: классификация (есть продажа?) + регрессия (сколько?)\n",
    "### 5.5 Ансамбль моделей"
   ],
   "id": "27bc97457e5b0dfd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================\n",
    "# 5.1 Baseline: среднее за последние 7 дней (qty_rmean_7)\n",
    "# ============================================================\n",
    "baseline_pred = val[\"qty_rmean_7\"].fillna(0).values\n",
    "baseline_wmae = weighted_mae(y_val, baseline_pred)\n",
    "baseline_mae = np.mean(np.abs(y_val - baseline_pred))\n",
    "\n",
    "print(f\"Baseline (rmean_7):\")\n",
    "print(f\"  MAE:  {baseline_mae:.4f}\")\n",
    "print(f\"  wMAE: {baseline_wmae:.4f}\")"
   ],
   "id": "db79afbeb1e36075"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================\n",
    "# 5.2 LightGBM\n",
    "# ============================================================\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_params = {\n",
    "    \"objective\": \"regression_l1\",  # MAE loss (ближе к метрике)\n",
    "    \"metric\": \"mae\",\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 63,\n",
    "    \"max_depth\": -1,\n",
    "    \"min_child_samples\": 30,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"reg_alpha\": 0.1,\n",
    "    \"reg_lambda\": 1.0,\n",
    "    \"n_estimators\": 3000,\n",
    "    \"random_state\": 42,\n",
    "    \"verbose\": -1,\n",
    "    \"n_jobs\": -1,\n",
    "}\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(**lgb_params)\n",
    "lgb_model.fit(\n",
    "    X_tr, y_tr,\n",
    "    sample_weight=w_tr,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_sample_weight=[w_val],\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(100, verbose=True),\n",
    "        lgb.log_evaluation(200),\n",
    "    ],\n",
    ")\n",
    "\n",
    "lgb_val_pred = lgb_model.predict(X_val)\n",
    "lgb_val_pred = np.clip(lgb_val_pred, 0, None)\n",
    "\n",
    "print(f\"\\nLightGBM:\")\n",
    "print(f\"  MAE:  {np.mean(np.abs(y_val - lgb_val_pred)):.4f}\")\n",
    "print(f\"  wMAE: {weighted_mae(y_val, lgb_val_pred):.4f}\")\n",
    "print(f\"  Best iteration: {lgb_model.best_iteration_}\")"
   ],
   "id": "d4ffc47c2bd83f70"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Feature importance (LightGBM)\n",
    "fi = pd.DataFrame({\n",
    "    \"feature\": feature_cols,\n",
    "    \"importance\": lgb_model.feature_importances_\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.barh(fi[\"feature\"].head(25)[::-1], fi[\"importance\"].head(25)[::-1])\n",
    "ax.set_title(\"LightGBM — Top-25 Feature Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "display(fi.head(15))"
   ],
   "id": "3a95c2825ad817e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================\n",
    "# 5.3 CatBoost (с взвешенным eval через Pool)\n",
    "# ============================================================\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "cb_train_pool = Pool(X_tr, y_tr, weight=w_tr)\n",
    "cb_val_pool = Pool(X_val, y_val, weight=w_val)\n",
    "\n",
    "cb_model = CatBoostRegressor(\n",
    "    loss_function=\"MAE\",\n",
    "    iterations=3000,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    l2_leaf_reg=3.0,\n",
    "    subsample=0.8,\n",
    "    random_seed=42,\n",
    "    early_stopping_rounds=100,\n",
    "    verbose=200,\n",
    ")\n",
    "\n",
    "cb_model.fit(cb_train_pool, eval_set=cb_val_pool)\n",
    "\n",
    "cb_val_pred = cb_model.predict(X_val)\n",
    "cb_val_pred = np.clip(cb_val_pred, 0, None)\n",
    "\n",
    "print(f\"\\nCatBoost:\")\n",
    "print(f\"  MAE:  {np.mean(np.abs(y_val - cb_val_pred)):.4f}\")\n",
    "print(f\"  wMAE: {weighted_mae(y_val, cb_val_pred):.4f}\")\n",
    "print(f\"  Best iteration: {cb_model.get_best_iteration()}\")"
   ],
   "id": "8e478e0299c2b248"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================\n",
    "# 5.4 Two-stage: классификация + регрессия\n",
    "# ============================================================\n",
    "\n",
    "# Stage 1: Будет ли продажа? (binary classification)\n",
    "y_tr_cls = (y_tr > 0).astype(int)\n",
    "y_val_cls = (y_val > 0).astype(int)\n",
    "\n",
    "cls_model = lgb.LGBMClassifier(\n",
    "    objective=\"binary\",\n",
    "    metric=\"binary_logloss\",\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=63,\n",
    "    min_child_samples=30,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    n_estimators=2000,\n",
    "    random_state=42,\n",
    "    verbose=-1,\n",
    "    n_jobs=-1,\n",
    "    scale_pos_weight=7.0,  # баланс классов\n",
    ")\n",
    "cls_model.fit(\n",
    "    X_tr, y_tr_cls,\n",
    "    eval_set=[(X_val, y_val_cls)],\n",
    "    callbacks=[lgb.early_stopping(100), lgb.log_evaluation(500)],\n",
    ")\n",
    "\n",
    "cls_proba = cls_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Stage 2: Регрессия только на ненулевых\n",
    "tr_pos = tr[y_tr > 0]\n",
    "X_tr_pos = tr_pos[feature_cols]\n",
    "y_tr_pos = tr_pos[\"qty\"]\n",
    "\n",
    "reg_model = lgb.LGBMRegressor(\n",
    "    objective=\"regression_l1\",\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=63,\n",
    "    min_child_samples=20,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    n_estimators=2000,\n",
    "    random_state=42,\n",
    "    verbose=-1,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "val_pos = val[y_val > 0]\n",
    "X_val_pos = val_pos[feature_cols]\n",
    "y_val_pos = val_pos[\"qty\"]\n",
    "\n",
    "reg_model.fit(\n",
    "    X_tr_pos, y_tr_pos,\n",
    "    eval_set=[(X_val_pos, y_val_pos)],\n",
    "    callbacks=[lgb.early_stopping(100), lgb.log_evaluation(500)],\n",
    ")\n",
    "\n",
    "# Комбинируем: P(sale) * E[qty | sale]\n",
    "reg_pred_all = reg_model.predict(X_val)\n",
    "reg_pred_all = np.clip(reg_pred_all, 0, None)\n",
    "\n",
    "# Подбираем порог для классификации\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "best_thr, best_wmae_2s = 0.5, float(\"inf\")\n",
    "for thr in np.arange(0.05, 0.95, 0.05):\n",
    "    pred_2s = np.where(cls_proba >= thr, reg_pred_all, 0.0)\n",
    "    wm = weighted_mae(y_val, pred_2s)\n",
    "    if wm < best_wmae_2s:\n",
    "        best_thr = thr\n",
    "        best_wmae_2s = wm\n",
    "\n",
    "two_stage_pred = np.where(cls_proba >= best_thr, reg_pred_all, 0.0)\n",
    "\n",
    "print(f\"\\nTwo-stage (threshold={best_thr:.2f}):\")\n",
    "print(f\"  MAE:  {np.mean(np.abs(y_val - two_stage_pred)):.4f}\")\n",
    "print(f\"  wMAE: {best_wmae_2s:.4f}\")"
   ],
   "id": "9b48ca2545c43ea9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================\n",
    "# 5.5 Ансамбль — подбор весов на валидации\n",
    "# ============================================================\n",
    "print(\"Сводка по моделям на валидации:\")\n",
    "print(f\"  Baseline (rmean_7):  wMAE = {baseline_wmae:.4f}\")\n",
    "print(f\"  LightGBM:            wMAE = {weighted_mae(y_val, lgb_val_pred):.4f}\")\n",
    "print(f\"  CatBoost:            wMAE = {weighted_mae(y_val, cb_val_pred):.4f}\")\n",
    "print(f\"  Two-stage:           wMAE = {best_wmae_2s:.4f}\")\n",
    "\n",
    "# Grid-search весов для блендинга LGB + CB + Two-stage\n",
    "best_blend_wmae = float(\"inf\")\n",
    "best_w = (1.0, 0.0, 0.0)\n",
    "\n",
    "for w1 in np.arange(0, 1.05, 0.1):\n",
    "    for w2 in np.arange(0, 1.05 - w1, 0.1):\n",
    "        w3 = round(1.0 - w1 - w2, 2)\n",
    "        if w3 < 0:\n",
    "            continue\n",
    "        blend = w1 * lgb_val_pred + w2 * cb_val_pred + w3 * two_stage_pred\n",
    "        blend = np.clip(blend, 0, None)\n",
    "        wm = weighted_mae(y_val, blend)\n",
    "        if wm < best_blend_wmae:\n",
    "            best_blend_wmae = wm\n",
    "            best_w = (round(w1, 2), round(w2, 2), round(w3, 2))\n",
    "\n",
    "print(f\"\\nЛучший ансамбль: LGB={best_w[0]}, CB={best_w[1]}, 2-stage={best_w[2]}\")\n",
    "print(f\"  wMAE = {best_blend_wmae:.4f}\")"
   ],
   "id": "6b58d8fa0a371e46"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================\n",
    "# 5.6 Переобучение на ПОЛНОМ train (включая валидацию)\n",
    "# ============================================================\n",
    "# Модели выше обучены без последних 14 дней (валидация).\n",
    "# Для финального предсказания переобучаем на всём train,\n",
    "# используя лучшее число итераций, найденное на валидации.\n",
    "\n",
    "train_all = df[(df[\"is_test\"] == 0) & (df[\"dt\"] >= df[\"dt\"].min() + pd.Timedelta(days=28))].copy()\n",
    "X_all = train_all[feature_cols]\n",
    "y_all = train_all[\"qty\"]\n",
    "w_all = np.where(y_all > 0, 7.0, 1.0)\n",
    "\n",
    "print(f\"Переобучение на полном train: {len(X_all):,} строк\")\n",
    "print(f\"  Период: {train_all['dt'].min().date()} — {train_all['dt'].max().date()}\")\n",
    "\n",
    "# LightGBM\n",
    "print(\"\\n[1/4] LightGBM...\")\n",
    "lgb_final = lgb.LGBMRegressor(**{**lgb_params, \"n_estimators\": lgb_model.best_iteration_})\n",
    "lgb_final.fit(X_all, y_all, sample_weight=w_all)\n",
    "\n",
    "# CatBoost\n",
    "print(\"[2/4] CatBoost...\")\n",
    "cb_final = CatBoostRegressor(\n",
    "    loss_function=\"MAE\",\n",
    "    iterations=cb_model.get_best_iteration(),\n",
    "    learning_rate=0.05, depth=6, l2_leaf_reg=3.0,\n",
    "    subsample=0.8, random_seed=42, verbose=0,\n",
    ")\n",
    "cb_final.fit(Pool(X_all, y_all, weight=w_all))\n",
    "\n",
    "# Two-stage classifier\n",
    "print(\"[3/4] Two-stage classifier...\")\n",
    "cls_final = lgb.LGBMClassifier(\n",
    "    objective=\"binary\", learning_rate=0.05, num_leaves=63,\n",
    "    min_child_samples=30, subsample=0.8, colsample_bytree=0.8,\n",
    "    n_estimators=max(cls_model.best_iteration_, 50),\n",
    "    scale_pos_weight=7.0, random_state=42, verbose=-1, n_jobs=-1,\n",
    ")\n",
    "cls_final.fit(X_all, (y_all > 0).astype(int))\n",
    "\n",
    "# Two-stage regressor\n",
    "print(\"[4/4] Two-stage regressor...\")\n",
    "pos_mask = y_all > 0\n",
    "reg_final = lgb.LGBMRegressor(\n",
    "    objective=\"regression_l1\", learning_rate=0.05, num_leaves=63,\n",
    "    min_child_samples=20, subsample=0.8, colsample_bytree=0.8,\n",
    "    n_estimators=max(reg_model.best_iteration_, 50),\n",
    "    random_state=42, verbose=-1, n_jobs=-1,\n",
    ")\n",
    "reg_final.fit(X_all[pos_mask], y_all[pos_mask])\n",
    "\n",
    "print(\"\\nВсе модели переобучены на полном train.\")"
   ],
   "id": "3b50c44d9720c137"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 6. Предсказание и сабмит\n",
    "- Переобученные модели на **полном train** (включая период валидации)\n",
    "- Forward-fill лаговых фичей (вместо 93% NaN)\n",
    "- Клиппинг: qty >= 0, qty <= prev_leftovers\n",
    "- **БЕЗ округления** — дробные предсказания оптимальнее для MAE"
   ],
   "id": "58da2eafe6976c7a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================\n",
    "# 6.1 Предсказание на test (переобученные модели, без рекурсии)\n",
    "# ============================================================\n",
    "test_df = df[df[\"is_test\"] == 1].copy()\n",
    "X_test = test_df[feature_cols]\n",
    "\n",
    "# LightGBM (переобученный на полном train)\n",
    "lgb_test_pred = lgb_final.predict(X_test)\n",
    "lgb_test_pred = np.clip(lgb_test_pred, 0, None)\n",
    "\n",
    "# CatBoost (переобученный на полном train)\n",
    "cb_test_pred = cb_final.predict(X_test)\n",
    "cb_test_pred = np.clip(cb_test_pred, 0, None)\n",
    "\n",
    "# Two-stage (переобученный на полном train)\n",
    "cls_test_proba = cls_final.predict_proba(X_test)[:, 1]\n",
    "reg_test_pred = reg_final.predict(X_test)\n",
    "reg_test_pred = np.clip(reg_test_pred, 0, None)\n",
    "two_stage_test_pred = np.where(cls_test_proba >= best_thr, reg_test_pred, 0.0)\n",
    "\n",
    "# Ансамбль с лучшими весами\n",
    "w1, w2, w3 = best_w\n",
    "final_pred = w1 * lgb_test_pred + w2 * cb_test_pred + w3 * two_stage_test_pred\n",
    "\n",
    "print(f\"Ансамбль: LGB*{w1} + CB*{w2} + 2-stage*{w3}\")\n",
    "print(f\"Предсказания: min={final_pred.min():.3f}, max={final_pred.max():.3f}, mean={final_pred.mean():.3f}\")"
   ],
   "id": "6fac95b59b1dc62"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================\n",
    "# 6.2 Постобработка\n",
    "# ============================================================\n",
    "\n",
    "# Клиппинг: не больше остатков на складе\n",
    "test_leftovers = test_df[\"prev_leftovers\"].values\n",
    "final_pred = np.clip(final_pred, 0, test_leftovers)\n",
    "\n",
    "# НЕ округляем — дробные предсказания дают лучший MAE\n",
    "print(f\"После постобработки:\")\n",
    "print(f\"  min={final_pred.min():.3f}, max={final_pred.max():.3f}, mean={final_pred.mean():.3f}\")\n",
    "print(f\"  Доля нулей: {(final_pred == 0).mean():.1%}\")\n",
    "print(f\"  Доля > 0: {(final_pred > 0).mean():.1%}\")"
   ],
   "id": "468ed630b1e79c61"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================\n",
    "# 6.3 Формирование submission\n",
    "# ============================================================\n",
    "\n",
    "submission = sub.copy()\n",
    "submission[\"qty\"] = 0.0  # default (float, не int!)\n",
    "\n",
    "# Маппинг предсказаний по (nm_id, dt)\n",
    "test_df[\"pred_qty\"] = final_pred\n",
    "pred_map = test_df.set_index([\"nm_id\", \"dt\"])[\"pred_qty\"]\n",
    "\n",
    "submission[\"dt\"] = pd.to_datetime(submission[\"dt\"])\n",
    "submission = submission.set_index([\"nm_id\", \"dt\"])\n",
    "submission[\"qty\"] = pred_map\n",
    "submission = submission.reset_index()\n",
    "\n",
    "# Заполняем NaN нулями (товары без предсказаний)\n",
    "submission[\"qty\"] = submission[\"qty\"].fillna(0.0)\n",
    "\n",
    "# Проверка\n",
    "assert len(submission) == len(sub), f\"Длина не совпадает: {len(submission)} vs {len(sub)}\"\n",
    "assert submission[\"qty\"].isnull().sum() == 0, \"Есть NaN в предсказаниях!\"\n",
    "\n",
    "print(f\"Submission shape: {submission.shape}\")\n",
    "print(f\"Пример:\")\n",
    "display(submission.head(10))\n",
    "\n",
    "# Сохраняем\n",
    "output_path = \"/Users/slvic/Downloads/submission_2.csv\"\n",
    "submission.to_csv(output_path, index=False)\n",
    "print(f\"\\nСохранено: {output_path}\")"
   ],
   "id": "6bcd59b6c9365e59"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Итоги\n",
    "\n",
    "| Модель | wMAE (val) |\n",
    "|--------|-----------|\n",
    "| Baseline (rmean_7) | см. выше |\n",
    "| LightGBM | см. выше |\n",
    "| CatBoost | см. выше |\n",
    "| Two-stage (cls + reg) | см. выше |\n",
    "| **Ансамбль** | **лучший** |\n",
    "\n",
    "**Улучшения (v3):**\n",
    "1. **Forward-fill лаговых фичей** — вместо 93% NaN в тесте, лаги заполняются последними известными значениями\n",
    "2. **Переобучение на полном train** — финальные модели обучены на всех данных (включая валидационный период)\n",
    "3. **CatBoost с взвешенным eval** — early stopping через Pool с весами\n",
    "4. **Без округления** — float-предсказания оптимальнее для MAE\n",
    "5. **Индикатор устаревшости** — фича `days_since_train`\n",
    "\n",
    "**Убрано (ухудшало):**\n",
    "- ~~Клиппинг выбросов~~ — обрезал таргет на валидации, модель не могла предсказать высокие продажи\n",
    "- ~~Рекурсивное предсказание~~ — накопление ошибок от дня к дню (mean рос с 1.08 до 1.99)"
   ],
   "id": "af4782c8f638f15f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
